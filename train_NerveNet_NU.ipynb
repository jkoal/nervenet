{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from classifiers.NerveNet_NU import NerveNET\n",
    "from data_utils_NerveNet_NU import SegmentationData\n",
    "from solver_NerveNet_NU import Solver\n",
    "import transform_utils_NerveNet as tu\n",
    "from dice_loss_NU import DiceLoss\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following calculates the **sizes of train, validation and test set**. Make sure it returns **True** by modifying the values in the dictionary 'nums'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_train': 1278, 'num_val': 425, 'num_test': 425} 2128\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "img_files = 'image_files.txt'\n",
    "num_lines = sum(1 for line in open(img_files, 'r'))\n",
    "nums = {'num_train' : int(0.6*num_lines)+2,\n",
    "        'num_val'   : int(0.2*num_lines),\n",
    "        'num_test' : int(0.2*num_lines)}\n",
    "\n",
    "print(nums, num_lines)\n",
    "print(np.sum(list(nums.values())) == num_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New in dataloader**: \n",
    "1. The dataloader has the new flag **binary_out**. If True, it will return a binary value that is if a nerve mask is contained in the target or not. Calling e.g. train_data[0] will return inputs and targets, where targets is now a dictionary with keys **'main'** and **'binary'**, if binary_out is True.\n",
    "2. The text file that contains the image id's can now be in the git project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = (1, 128, 128)\n",
    "\n",
    "train_transforms = tu.Compose([tu.Resize(input_dim[1::]),\n",
    "                               tu.RandomHorizontalFlip(),\n",
    "                               tu.RandomVerticalFlip(),\n",
    "                               tu.ToTensor()])\n",
    "\n",
    "val_transforms = tu.Compose([tu.Resize(input_dim[1::]),\n",
    "                               tu.ToTensor()])\n",
    "\n",
    "\n",
    "train_data = SegmentationData(img_files, transform = train_transforms, mode = 'train', **nums, binary_out = True)\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=4,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4)\n",
    "\n",
    "val_data = SegmentationData(img_files,  transform = val_transforms, mode = 'val', **nums)\n",
    "val_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=4,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New in classifier**: \n",
    "1. NerveNet has a new **binary_out** flag, too. If True, the forward pass will calculate a binary output. Similarly the output of the forward pass is a dictionary with keys 'main' and 'binary'.\n",
    "2. The argument **upsample_unit** is a switch between simple upsampling with bilinear interpolation and transposed convolutional layers. Must be either **'Upsample'** or **'ConvTranspose2d'**. Default is 'Upsample'.\n",
    "3. **Xavier Normal Initialization** is automatically applied to all NerveNet layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NerveNET(input_dim, num_classes = 2, weight_scale = True, dropout = 0.15, \n",
    "                 binary_out = False, upsample_unit='Upsample')\n",
    "#model = torch.load(\"models/NerveNet_NU.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New in solver**:\n",
    "1. Solver exspects new **binary_out** argument. Here, it should be a float value, that gives the weight of the loss of the binary output. The main output is implicitly weighted with one, so that **binary_out** should be **smaller than one**. If **binary_out** is equal to **zero**, **no binary loss** will be computed.\n",
    "2. Train and validation are two seperate functions which seems to be more memory efficient and clearly structured.\n",
    "3. Printing loss and accuracy were wrapped in seperate functions, too, to further enhance readability of the code.\n",
    "\n",
    "**New in DiceLoss**:\n",
    "1. DiceLoss now calculates and automatically detects the loss on **doubleclass input** (Batchsize, Classes = 2, H, W) with single class target (Batchsize, Classes = 1, H, W) by inverting the target for Class = 0 and adding losses for both classes.\n",
    "2. The argument **classweights** receives weights for losses from class 0 and class 1, respectively. Default is [1, 1].\n",
    "3. **Singleclass input** still doable. E.g. initialize model with **num_classes = 1** will work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAIN.\n",
      "|Iteration 10/320| TRAIN loss: 1.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-14:\n",
      "Process Process-13:\n",
      "Process Process-16:\n",
      "Traceback (most recent call last):\n",
      "Process Process-15:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-15391b01e5e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_nth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jlappalainen/Dokumente/Deep Learning for Computer Vision/project/nervenet/solver_NerveNet_NU.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, train_loader, val_loader, num_epochs, log_nth)\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbinary_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for param in list(model.parameters()):\n",
    "#    param.requires_grad = False\n",
    "    \n",
    "#for param in list(model.parameters())[0:50]:\n",
    "#    param.requires_grad = True\n",
    "\n",
    "solver = Solver(optim_args={\"lr\": 0.05, #0.0025, #1.e-3, #1.e-2\n",
    "                            \"betas\": (0.9, 0.999),\n",
    "                            \"eps\": 1e-8,\n",
    "                            \"weight_decay\": 0.},\n",
    "                loss_func = DiceLoss(classweights = [1, 1]), binary_out = 0)\n",
    "\n",
    "model.train()\n",
    "outputs = solver.train(model, train_loader, val_loader, log_nth=10, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/NerveNet_NU.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_files = 'image_files.txt'\n",
    "\n",
    "\n",
    "test_data = SegmentationData(img_files,  transform = val_transforms, mode = 'test', **nums)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size=4,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "img, targets = test_data[5]\n",
    "\n",
    "target = targets['main']\n",
    "inputs = img.unsqueeze(0)\n",
    "inputs = Variable(inputs)\n",
    "\n",
    "model=model.cpu()\n",
    "\n",
    "outputs = model.forward(inputs)\n",
    "pred = outputs['main']\n",
    "_, pred = torch.max(pred, 1)\n",
    "pred = pred.squeeze().data.cpu().numpy()\n",
    "img=np.squeeze(img)\n",
    "target = target.squeeze().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].imshow(img)\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(target)\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(np.where(pred>0.1, 1, 0))\n",
    "ax[2].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_example_imgs = 10\n",
    "plt.figure(figsize=(15, 5 * num_example_imgs))\n",
    "for i, (img, targets) in enumerate(test_data[90:100]):\n",
    "    \n",
    "    target = targets['main']\n",
    "    inputs = img.unsqueeze(0)\n",
    "    inputs = Variable(inputs)\n",
    "\n",
    "    outputs = model.forward(inputs)\n",
    "    pred = outputs['main']\n",
    "    _, pred = torch.max(pred, 1)\n",
    "    pred = pred.squeeze().data.cpu().numpy()\n",
    "\n",
    "    img=np.squeeze(img)\n",
    "    target = target.squeeze().numpy()\n",
    "        \n",
    "    # img\n",
    "    plt.subplot(num_example_imgs, 3, i * 3 + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    if i == 0:\n",
    "        plt.title(\"Input image\")\n",
    "    \n",
    "    # target\n",
    "    plt.subplot(num_example_imgs, 3, i * 3 + 2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(target, cmap='gray')\n",
    "    if i == 0:\n",
    "        plt.title(\"Target image\")\n",
    "\n",
    "    # pred\n",
    "    plt.subplot(num_example_imgs, 3, i * 3 + 3)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(pred, cmap='gray')\n",
    "    if i == 0:\n",
    "        plt.title(\"Prediction image\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(ground_truth, predicted):\n",
    "    gt = ground_truth\n",
    "    p = predicted\n",
    "    if np.sum(p) + np.sum(gt) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        dice = np.sum(p[gt==1])*2.0 / (np.sum(p) + np.sum(gt))\n",
    "        return dice\n",
    "\n",
    "test_scores = []\n",
    "model.eval()\n",
    "for inputs, targets in test_loader:\n",
    "    inputs, targets = Variable(inputs), Variable(targets['main'])\n",
    "    if model.is_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    \n",
    "    outputs = model.forward(inputs)\n",
    "    pred = outputs['main']\n",
    "    _, pred = torch.max(pred, 1)\n",
    "    pred = pred.squeeze().data.cpu().numpy()\n",
    "    test_scores.append(dice_coefficient(np.squeeze(targets.data.numpy()), pred))\n",
    "    \n",
    "model.train()\n",
    "np.mean(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array(test_scores)\n",
    "x[x==1] = 0\n",
    "np.argmax(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
