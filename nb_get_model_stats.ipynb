{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from data_utils_NerveNet import SegmentationData\n",
    "from data_utils_SegNet import SegmentationData as SegData\n",
    "import transform_utils_NerveNet as tu\n",
    "\n",
    "import get_model_stats as gs\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_train': 1278, 'num_val': 425, 'num_test': 425} 2128\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "img_files = 'image_files.txt' \n",
    "num_lines = sum(1 for line in open(img_files, 'r'))\n",
    "num_lines = sum(1 for line in open(img_files, 'r'))\n",
    "nums = {'num_train' : int(0.6*num_lines)+2,\n",
    "        'num_val'   : int(0.2*num_lines),\n",
    "        'num_test' : int(0.2*num_lines)}\n",
    "\n",
    "print(nums, num_lines)\n",
    "print(np.sum(list(nums.values())) == num_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = (1, 128, 128)\n",
    "model_names = ['NerveNet', 'NerveNet_binary', 'SegNet', 'SegNet_binary', 'NerveNet_binary_iGAN']\n",
    "\n",
    "#model_path = 'models/' + model_name + '.model'\n",
    "#model = torch.load(model_path, map_location=lambda storage, loc: storage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (1, 128, 128)\n",
    "test_transforms = tu.Compose([tu.Resize(input_dim[1::]),\n",
    "                               tu.ToTensor()])\n",
    "for mname in model_names:\n",
    "    model_path = 'models/' + mname + '.model'\n",
    "    model = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "    if 'Seg' in mname:\n",
    "        test_data = SegData(img_files,  transform = test_transforms, mode = 'test', **nums)\n",
    "    else:\n",
    "        test_data = SegmentationData(img_files,  transform = test_transforms, mode = 'test', **nums)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False, num_workers=4)\n",
    "    if 'binary' in mname:\n",
    "        model.binary_out = True\n",
    "    else:\n",
    "        model.binary_out = False\n",
    "    model.eval()\n",
    "    stats = gs.get_model_stats(model, test_loader)\n",
    "    print('Accuracy of %s is %s'%(mname, stats['accuracy']))\n",
    "    np.save('stats/%s'%mname+'.stats', stats)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdict = {}\n",
    "for mname in model_names:\n",
    "    stats = np.load('stats/%s'%mname+'.stats.npy').item()\n",
    "    mdict[mname] = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sens = []\n",
    "spec = []\n",
    "acc =  []\n",
    "for mnames in model_names:\n",
    "    sens.append(mdict[mnames]['sensitivity'])\n",
    "    spec.append(mdict[mnames]['specificity'])\n",
    "    acc.append(mdict[mnames]['accuracy'])\n",
    "    \n",
    "cs = {'b': (0.2980392156862745, 0.4470588235294118, 0.6901960784313725),\n",
    "     'g': (0.3333333333333333, 0.6588235294117647, 0.40784313725490196),\n",
    "     'r': (0.7686274509803922, 0.3058823529411765, 0.3215686274509804),\n",
    "     'v': (0.5058823529411764, 0.4470588235294118, 0.6980392156862745),\n",
    "     'y': (0.8, 0.7254901960784313, 0.4549019607843137),\n",
    "     'c': (0.39215686274509803, 0.7098039215686275, 0.803921568627451)}    \n",
    "    \n",
    "plt.figure(figsize=(7, 7))    \n",
    "    \n",
    "diameter = 5*np.pi * (15 * np.array(acc))**2\n",
    "colors = [cs['v'], cs['b'], cs['r'], cs['y'], cs['g']]\n",
    "plt.scatter(sens, spec, s=diameter, c=colors, alpha=0.7)\n",
    "plt.xlabel('Sensitivity', fontsize = 16)\n",
    "plt.ylabel('Specificity',fontsize = 16)\n",
    "#for i, mname in enumerate(model_names):\n",
    "#    ax = plt.gca()\n",
    "#    ax.annotate(mname, (sens[i],spec[i]))\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in mdict:\n",
    "    print(key, mdict[key]['highscore_index'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
